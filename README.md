# ì„¸ê·¸ë¨¼íŠ¸ ë¶„í• Â·ì§‘ê³„ ì „ëµì— ë”°ë¥¸ ìŒì•… ì„ë² ë”© í’ˆì§ˆì˜ ë¹„êµ ë¶„ì„

> **A Comparative Analysis of Music Embedding Quality Based on Segment Division and Aggregation Strategies**

## ğŸ“‹ Overview

ë³¸ ì—°êµ¬ëŠ” 2025ë…„ ê°€ì²œxì„¸ì¢… ì—°í•© í•™ìˆ ì œì˜ ì—°êµ¬íŒ€ TUNEì´ ì§„í–‰í•œ ì—°êµ¬ë¡œ, [MARBLE](https://github.com/a43992899/MARBLE) ë²¤ì¹˜ë§ˆí¬ì™€ [MuQ](https://github.com/tencent-ailab/MuQ) ì„ë² ë”© ë°±ë³¸ì„ í™œìš©í•˜ì—¬ ìŒì•… ì„ë² ë”© ìƒì„± ì‹œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  ë° ì§‘ê³„ ì „ëµì´ í’ˆì§ˆê³¼ íš¨ìœ¨ì„±ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•œ ì—°êµ¬ì…ë‹ˆë‹¤.

ìµœì‹  ìŒì•… ì„ë² ë”© ëª¨ë¸ë“¤ì€ íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ë¥¼ í†µí•´ ë†’ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆì§€ë§Œ, ê¸´ ì˜¤ë””ì˜¤ ì‹œí€€ìŠ¤ì— ëŒ€í•œ **O(NÂ²) ê³„ì‚° ë³µì¡ë„ ë¬¸ì œ**ë¡œ ì‹¤ìš©ì„±ì— í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í• Â·ì§‘ê³„ ì „ëµì„ ì •ëŸ‰ì ìœ¼ë¡œ ë¹„êµí•˜ì—¬, **ì„±ëŠ¥-íš¨ìœ¨ì„± íŠ¸ë ˆì´ë“œì˜¤í”„** ê´€ê³„ë¥¼ ê·œëª…í•©ë‹ˆë‹¤.

### ğŸ¯ Research Objectives

1. **ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ ì˜í–¥ ë¶„ì„**: 10ì´ˆ, 30ì´ˆ, 60ì´ˆ ë¶„í• ì´ ì„ë² ë”© í’ˆì§ˆì— ë¯¸ì¹˜ëŠ” ì˜í–¥
2. **ì§‘ê³„ ë°©ë²•ë¡  í‰ê°€**: Concatenate, Mean Pooling, Transformer ê¸°ë°˜ ì§‘ê³„ì˜ ì„±ëŠ¥-íš¨ìœ¨ì„± ë¹„êµ
3. **ì‹¤ìš©ì  ê°€ì´ë“œë¼ì¸ ì œì‹œ**: ì œí•œëœ ê³„ì‚° ìì› í™˜ê²½ì—ì„œì˜ ìµœì  ì „ëµ ë„ì¶œ

## ğŸ—ï¸ Architecture & Models

### Base Models
- **MuQ (Music Understanding with Quantization)**: ë©œ ìŠ¤í™íŠ¸ëŸ¼ ê¸°ë°˜ Residual Vector Quantizationì„ í™œìš©í•œ ìê°€ì§€ë„ ìŒì•… í‘œí˜„ í•™ìŠµ ëª¨ë¸
- **MARBLE**: ìŒì•… í‘œí˜„ í•™ìŠµì˜ ë²”ìš© í‰ê°€ë¥¼ ìœ„í•œ í‘œì¤€í™”ëœ ë²¤ì¹˜ë§ˆí¬

### Experimental Framework

| ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ | ì§‘ê³„ ì „ëµ | ì„¤ëª… | íŠ¹ì§• |
|-------------|----------|------|------|
| **10ì´ˆ** | Concatenate | ì„¸ê·¸ë¨¼íŠ¸ ë²¡í„° ìˆœì°¨ ì—°ê²° | ì°¨ì› ì¦ê°€, ë†’ì€ ë©”ëª¨ë¦¬ ìš”êµ¬ |
| **10ì´ˆ** | Mean Pooling | ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© í‰ê·  | íš¨ìœ¨ì , ì•ˆì •ì  ì„±ëŠ¥ |
| **10ì´ˆ** | Transformer | Self-attention ê¸°ë°˜ ì§‘ê³„ | ê´€ê³„ ëª¨ë¸ë§, ì œí•œëœ ì‚¬ì „í•™ìŠµ |
| **30ì´ˆ** | (ìœ„ 3ê°€ì§€ ì§‘ê³„ ë°©ì‹ ë™ì¼ ì ìš©) | ì¤‘ê°„ ê¸¸ì´ ì»¨í…ìŠ¤íŠ¸ | ê· í˜•ì¡íŒ ì •ë³´ëŸ‰ |
| **60ì´ˆ** | (ìœ„ 3ê°€ì§€ ì§‘ê³„ ë°©ì‹ ë™ì¼ ì ìš©) | ê¸´ ì»¨í…ìŠ¤íŠ¸ | êµ¬ì¡°ì  ì •ë³´ í¬í•¨ |
| **ì „ì²´ íŠ¸ë™** | - | ë¶„í•  ì—†ì´ ì§ì ‘ ì²˜ë¦¬ | ë² ì´ìŠ¤ë¼ì¸ (ì´ìƒì  ì„±ëŠ¥) |

## ğŸ“ Project Structure

```
TUNE/
â”œâ”€â”€ configs/                    # Lightning CLI ì„¤ì • íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ probe.EMO.MuQMax10sec.yaml      # Max pooling ê¸°ë°˜ 10ì´ˆ ì„¸ê·¸ë¨¼íŠ¸
â”‚   â”œâ”€â”€ probe.EMO.MuQMean10sec.yaml     # Mean pooling ê¸°ë°˜ 10ì´ˆ ì„¸ê·¸ë¨¼íŠ¸  
â”‚   â”œâ”€â”€ probe.EMO.MuQSegment.yaml       # ê¸°ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬
â”‚   â”œâ”€â”€ probe.EMO.Transformer10sec.yaml # íŠ¸ëœìŠ¤í¬ë¨¸ ì§‘ê³„ 10ì´ˆ
â”‚   â”œâ”€â”€ probe.EMO.Transformer30sec.yaml # íŠ¸ëœìŠ¤í¬ë¨¸ ì§‘ê³„ 30ì´ˆ
â”‚   â””â”€â”€ probe.EMO.Transformer60sec.yaml # íŠ¸ëœìŠ¤í¬ë¨¸ ì§‘ê³„ 60ì´ˆ
â”œâ”€â”€ marble/
â”‚   â””â”€â”€ encoders/               # ì»¤ìŠ¤í…€ ì¸ì½”ë” êµ¬í˜„
â”‚       â”œâ”€â”€ muq_max_10sec_encoder.py
â”‚       â”œâ”€â”€ muq_mean_10sec_encoder.py
â”‚       â”œâ”€â”€ muq_segment_encoder.py
â”‚       â”œâ”€â”€ transformer_segment_encoder.py          # 60ì´ˆ ì„¸ê·¸ë¨¼íŠ¸
â”‚       â”œâ”€â”€ transformer_segment_encoder_10sec.py
â”‚       â””â”€â”€ transformer_segment_encoder_30sec.py
â””â”€â”€ data/
    â”œâ”€â”€ EMO/                    # ê°ì • ì¸ì‹ ë°ì´í„°ì…‹
    â”‚   â”œâ”€â”€ EMO.train.jsonl
    â”‚   â”œâ”€â”€ EMO.val.jsonl
    â”‚   â””â”€â”€ EMO.test.jsonl
    â””â”€â”€ GTZAN/                  # ì¥ë¥´ ë¶„ë¥˜ ë°ì´í„°ì…‹
```

## ğŸ”¬ Methodology

### 1. ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± (Segmentation Strategy)

ì „ì²´ ìŒì•… íŠ¸ë™ X (ê¸¸ì´ T)ë¥¼ ê³ ì • ê¸¸ì´ L âˆˆ {10, 30, 60}ì´ˆ ë‹¨ìœ„ë¡œ ë¶„í• :

```
X â†’ {xâ‚, xâ‚‚, ..., xâ‚™}, where N = âŒˆT/LâŒ‰
ê° ì„¸ê·¸ë¨¼íŠ¸: záµ¢ = f_Î¸(xáµ¢) âˆˆ â„áµˆ
```

### 2. ì§‘ê³„ ì „ëµ (Aggregation Strategies)

#### **Concatenation**
```
z = [zâ‚ | zâ‚‚ | ... | zâ‚™] âˆˆ â„^(Nd)
```

#### **Mean Pooling**  
```
z = (1/N) Î£áµ¢â‚Œâ‚â¿ záµ¢
```

#### **Transformer-based Aggregation**
```
z = TransformerAgg(Z)
```
- 4ì¸µ ì¸ì½”ë”, self-attention ë©”ì»¤ë‹ˆì¦˜
- MLM(Masked Language Modeling) ì‚¬ì „í•™ìŠµ (1 epoch)
- [CLS] í† í° ê¸°ë°˜ ìµœì¢… ì§‘ê³„

### 3. ë°±ë³¸ ê³ ì • (Frozen Backbone)

- MuQ ëª¨ë¸ íŒŒë¼ë¯¸í„° ì™„ì „ ê³ ì •
- ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ìš© ê²½ëŸ‰ ì˜ˆì¸¡ í—¤ë“œë§Œ í•™ìŠµ
- ì„±ëŠ¥ ì°¨ì´ê°€ ìˆœìˆ˜í•˜ê²Œ ë¶„í• Â·ì§‘ê³„ ì „ëµì—ì„œ ê¸°ì¸í•˜ë„ë¡ í†µì œ

## ğŸ“Š Experimental Results

### MARBLE ë²¤ì¹˜ë§ˆí¬ ì„±ëŠ¥ ê²°ê³¼

#### EMO Dataset (Emotion Recognition)
| ë°©ì‹ | ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ | Peak VRAM (GB) | ì¶”ë¡  ì‹œê°„ (sec) | RÂ²(Valence) | RÂ²(Arousal) |
|------|-------------|---------------|----------------|-------------|-------------|
| **ì „ì²´ íŠ¸ë™** | - | **6.816** | **45.845** | **0.574** | **0.737** |
| Concatenate | 10ì´ˆ | 9.730 | 136.986 | 0.547 | 0.760 |
| **Mean Pooling** | **10ì´ˆ** | **3.552** | **46.210** | **0.547** | **0.760** |
| Transformer | 10ì´ˆ | 4.095 | 60.886 | 0.492 | 0.707 |
| Mean Pooling | 30ì´ˆ | 4.124 | 62.352 | 0.542 | 0.756 |
| **Transformer** | **60ì´ˆ** | **4.132** | **45.707** | 0.506 | 0.726 |

#### GTZAN Dataset (Genre Classification)  
| ë°©ì‹ | ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ | Peak VRAM (GB) | ì¶”ë¡  ì‹œê°„ (sec) | Accuracy |
|------|-------------|---------------|----------------|----------|
| **ì „ì²´ íŠ¸ë™** | - | **6.546** | **60.678** | **0.845** |
| Concatenate | 10ì´ˆ | 9.361 | 181.427 | 0.828 |
| **Mean Pooling** | **10ì´ˆ** | **3.404** | **61.285** | **0.830** |
| Transformer | 10ì´ˆ | 3.932 | 80.702 | 0.795 |
| Mean Pooling | 30ì´ˆ | 3.928 | 82.522 | 0.835 |
| **Transformer** | **60ì´ˆ** | **3.968** | **55.980** | 0.805 |

## ğŸ” Key Findings

### 1. **ìµœì  ê· í˜•ì : Mean Pooling + 10~30ì´ˆ ì„¸ê·¸ë¨¼íŠ¸**
- **VRAM ì ˆì•½**: ì „ì²´ íŠ¸ë™ ëŒ€ë¹„ ì•½ 48% ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ
- **ì„±ëŠ¥ ë³´ì¡´**: ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥ì˜ 98% ì´ìƒ ìœ ì§€
- **ì‹¤ìš©ì„±**: ì œí•œëœ ìì› í™˜ê²½ì—ì„œ ê°€ì¥ íš¨ìœ¨ì 

### 2. **Concatenate ë°©ì‹ì˜ ë¹„íš¨ìœ¨ì„±**
- ëª¨ë“  ì¡°ê±´ì—ì„œ ê°€ì¥ ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ìµœëŒ€ 12.5GB)
- ì¶”ë¡  ì‹œê°„ ìµœëŒ€ 380% ì¦ê°€
- ì„±ëŠ¥ í–¥ìƒ ì—†ì´ ê³„ì‚° ë¹„ìš©ë§Œ ê¸‰ì¦

### 3. **Transformer ì§‘ê³„ì˜ íŠ¹ìˆ˜ì„±**
- ì œí•œëœ ì‚¬ì „í•™ìŠµ(1 epoch)ìœ¼ë¡œ ì„±ëŠ¥ ì €ì¡°
- **60ì´ˆ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ê°€ì¥ ë¹ ë¥¸ ì¶”ë¡  ì†ë„** (55.980ì´ˆ)
- ì ì€ ìˆ˜ì˜ ê¸´ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬ì— íŠ¹í™”

### 4. **ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ ì˜í–¥**
- ê¸´ ì„¸ê·¸ë¨¼íŠ¸ì¼ìˆ˜ë¡ ì„±ëŠ¥ ì†Œí­ í–¥ìƒ (ë” ë„“ì€ ì‹œê°„ì  ë¬¸ë§¥)
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ì¶”ë¡  ì‹œê°„ì€ ê¸¸ì´ì— ë¹„ë¡€í•˜ì—¬ ì¦ê°€

## âš™ï¸ Experimental Setup

### Hardware & Software
```bash
- GPU: NVIDIA RTX 2080 Ti
- Framework: PyTorch Lightning
- Random Seed: 1234 (ì¬í˜„ì„± ë³´ì¥)
```

### Datasets
- **GTZAN**: 1,000ê°œ íŠ¸ë™ (30ì´ˆ), 10ê°œ ì¥ë¥´, ì¥ë¥´ ë¶„ë¥˜
- **EMO**: 744ê³¡ (45ì´ˆ), Valence-Arousal ì—°ì†ê°’, ê°ì • ì¸ì‹

### Evaluation Metrics
- **ì„±ëŠ¥**: Accuracy (ë¶„ë¥˜), RÂ² Score (íšŒê·€)
- **íš¨ìœ¨ì„±**: Peak VRAM, ì¶”ë¡  ì‹œê°„
- **Trade-off**: ì •í™•ë„-íš¨ìœ¨ì„± ê· í˜• ë¶„ì„

## ğŸš€ Quick Start

### Prerequisites
```bash
pip install torch lightning torchmetrics librosa numpy psutil
# MuQ ëª¨ë¸ ì„¤ì¹˜ í•„ìš”
```

### Running Experiments

1. **Mean Pooling (ê¶Œì¥)**
```bash
python -m lightning.pytorch.cli fit --config configs/probe.EMO.MuQMean10sec.yaml
```

2. **Transformer ê¸°ë°˜**
```bash  
python -m lightning.pytorch.cli fit --config configs/probe.EMO.Transformer60sec.yaml
```

3. **ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**
```bash
python -m lightning.pytorch.cli test --config [CONFIG] --ckpt_path [CHECKPOINT]
```

## ğŸ“‹ Practical Guidelines

ë³¸ ì—°êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì‹¤ìš©ì  ê°€ì´ë“œë¼ì¸:

### ğŸ¯ **ìµœê³ ì˜ ê· í˜•ì  (ê¶Œì¥)**
- **ì „ëµ**: 10~30ì´ˆ ì„¸ê·¸ë¨¼íŠ¸ + Mean Pooling
- **ì ìš©**: ìì›ì´ ì œí•œëœ ëŒ€ë¶€ë¶„ì˜ í™˜ê²½
- **íš¨ê³¼**: ë©”ëª¨ë¦¬ 48% ì ˆì•½, ì„±ëŠ¥ 98% ë³´ì¡´

### ğŸ† **ì„±ëŠ¥ ìµœìš°ì„ **  
- **ì „ëµ**: ì „ì²´ íŠ¸ë™ ì§ì ‘ ì²˜ë¦¬
- **ì ìš©**: ì¶©ë¶„í•œ ê³„ì‚° ìì› ë³´ì¥ ì‹œ
- **íš¨ê³¼**: ì´ë¡ ì  ìµœê³  ì„±ëŠ¥

### âš¡ **ì†ë„ ìµœìš°ì„ **
- **ì „ëµ**: 60ì´ˆ ì„¸ê·¸ë¨¼íŠ¸ + Transformer ì§‘ê³„  
- **ì ìš©**: ì„±ëŠ¥ ì €í•˜ ê°ìˆ˜ ê°€ëŠ¥í•œ ì‹¤ì‹œê°„ í™˜ê²½
- **íš¨ê³¼**: ê°€ì¥ ë¹ ë¥¸ ì¶”ë¡  ì†ë„

## ğŸ”® Future Work

1. **íŠ¸ëœìŠ¤í¬ë¨¸ ì‚¬ì „í•™ìŠµ í™•ì¥**: 1 epoch â†’ ì¶©ë¶„í•œ í•™ìŠµìœ¼ë¡œ ì„±ëŠ¥ ê°œì„  ê°€ëŠ¥ì„±
2. **ì ì‘í˜• ë¶„í• **: ìŒì•…ì  êµ¬ì¡°(ë²ŒìŠ¤-ì½”ëŸ¬ìŠ¤) ê¸°ë°˜ ì˜ë¯¸ ë‹¨ìœ„ ë¶„í• 
3. **ë‹¤ì–‘í•œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬**: MARBLE ì „ì²´ ë²¤ì¹˜ë§ˆí¬ë¡œ í™•ì¥ í‰ê°€
4. **ê³„ì¸µì  ì§‘ê³„**: ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì‹œê°„ ì •ë³´ í†µí•© ì „ëµ

## ğŸ“š References

ë³¸ ì—°êµ¬ëŠ” ë‹¤ìŒ ì£¼ìš” ì—°êµ¬ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤:

- **MuQ**: Self-Supervised Music Representation Learning with Mel Residual Vector Quantization
- **MARBLE**: Music Audio Representation Benchmark for Universal Evaluation  
- **GTZAN**: Musical genre classification of audio signals
- **EMO**: 1000 songs for emotional analysis of music

## ğŸ‘¥ Contributors

- **ê³µìœ ë¹ˆ** (ê°€ì²œëŒ€í•™êµ ì¸ê³µì§€ëŠ¥í•™ê³¼)
- **ìœ¤ì¬í•˜** (ì„¸ì¢…ëŒ€í•™êµ ì¸ê³µì§€ëŠ¥í•™ê³¼)

## ğŸ“„ License

This project builds upon MARBLE and MuQ frameworks. Please refer to their respective licenses for usage guidelines.

---

**Keywords**: Music Information Retrieval, Segment Aggregation, Efficiency-Performance Trade-off, Audio Embeddings, Transformer
