seed_everything: 1234
ckpt_path: null # to resume

trainer:
  fast_dev_run: false
  accelerator: gpu
  # strategy: ddp # or ddp_find_unused_parameters
  devices: [0]
  accumulate_grad_batches: 4
  num_nodes: 1
  precision: bf16 # or 32, or 16
  max_epochs: 50
  check_val_every_n_epoch: 1
  num_sanity_val_steps: 10
  log_every_n_steps: 5

  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: "./output/probe.GS.Qwen2AudioInstructEncoder/checkpoints/" # Please specify your own path
        filename: "best"
        save_top_k: 1 # -1 to save all checkpoints
    - class_path: marble.modules.callbacks.LoadLatestCheckpointCallback # for testing
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
    - class_path: lightning.pytorch.callbacks.early_stopping.EarlyStopping
      init_args:
        monitor: "val/weighted_score"               # 要监控的 metric 名称
        patience: 20                       # 在多少次验证后无改进就停止
        mode: "max"                       # “val_loss” 下降时才算改进
  logger:
    class_path: lightning.pytorch.loggers.WandbLogger
    init_args:
      project: "marble"
      name: "probe.GS.Qwen2AudioInstructEncoder"
      save_dir: "./output/probe.GS.Qwen2AudioInstructEncoder/"


model:
  class_path: marble.tasks.GS.probe.ProbeAudioTask
  init_args:
    sample_rate: 16000
    use_ema: false

    encoder:
      class_path: marble.encoders.Qwen2AudioInstructEncoder.model.Qwen2AudioInstructEncoder
      init_args:
        pre_trained_folder: null
        train_mode: freeze  # also supports lora, or full
      
    emb_transforms:
      - class_path: marble.modules.transforms.LayerSelector
        init_args:
          layers: [32]  # something like [1, 3, "10..72"]
      - class_path: marble.modules.transforms.TimeAvgPool # (batch_size, num_layers, 1, hidden_size)
    
    decoders:
      - class_path: marble.modules.decoders.MLPDecoder
        init_args:
          in_dim: 1280
          out_dim: 24 # 24 KEYS
          hidden_layers: [512]
          activation_fn: 
            class_path: torch.nn.ReLU
          dropout: 0.2

    losses:
      - class_path: torch.nn.CrossEntropyLoss
        init_args:
          reduction: mean

    metrics:
      train:
        acc:
          class_path: torchmetrics.Accuracy
          init_args:
            num_classes: 24
            task: multiclass
        weighted_score:
          class_path: marble.tasks.GS.probe.KeyWeightedScore
      val:
        acc:
          class_path: torchmetrics.Accuracy
          init_args:
            num_classes: 24
            task: multiclass
        weighted_score:
          class_path: marble.tasks.GS.probe.KeyWeightedScore
      test:
        acc:
          class_path: torchmetrics.Accuracy
          init_args:
            num_classes: 24
            task: multiclass
        weighted_score:
          class_path: marble.tasks.GS.probe.KeyWeightedScore
    
data:
  class_path: marble.tasks.GS.datamodule.GSDataModule
  init_args:
    batch_size: 16
    num_workers: 8

    audio_transforms:
      train:
        - class_path: marble.encoders.Qwen2AudioInstructEncoder.model.Qwen2AudioInstructFeatureExtractor
          init_args:
            pre_trained_folder: null
            squeeze: true
      val:
        - class_path: marble.encoders.Qwen2AudioInstructEncoder.model.Qwen2AudioInstructFeatureExtractor
          init_args:
            pre_trained_folder: null
            squeeze: true
      test:
        - class_path: marble.encoders.Qwen2AudioInstructEncoder.model.Qwen2AudioInstructFeatureExtractor
          init_args:
            pre_trained_folder: null
            squeeze: true

    train:
      class_path: marble.tasks.GS.datamodule.GSAudioTrain
      init_args:
        sample_rate: 16000
        channels: 1
        clip_seconds: 30
        min_clip_ratio: 0.8 # at least 80% of the clip length
        channel_mode: first # first, random, mix
        jsonl: data/GS/GS.train.jsonl
    val:
      class_path: marble.tasks.GS.datamodule.GSAudioVal
      init_args:
        sample_rate: 16000
        channels: 1
        clip_seconds: 30
        min_clip_ratio: 0.8
        channel_mode: first
        jsonl: data/GS/GS.val.jsonl
    test:
      class_path: marble.tasks.GS.datamodule.GSAudioTest
      init_args:
        sample_rate: 16000
        channels: 1
        clip_seconds: 30
        min_clip_ratio: 0.8
        channel_mode: first
        jsonl: data/GS/GS.test.jsonl

optimizer:
  class_path: torch.optim.Adam
  init_args:
    lr: 1e-3

lr_scheduler:
  class_path: lightning.pytorch.cli.ReduceLROnPlateau
  init_args:
    mode: "max"
    factor: 0.1
    patience: 5
    monitor: "val/weighted_score"
