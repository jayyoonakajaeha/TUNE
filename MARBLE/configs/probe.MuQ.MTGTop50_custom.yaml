seed_everything: 1234
ckpt_path: null # to resume

trainer:
  fast_dev_run: false
  accelerator: gpu
  strategy: ddp
  devices: [0]
  accumulate_grad_batches: 1
  num_nodes: 1
  precision: bf16
  max_epochs: 20
  check_val_every_n_epoch: 1
  num_sanity_val_steps: 10
  log_every_n_steps: 5

  # [추가 1] 빠른 테스트를 위해 훈련/테스트 데이터 규모 제한 (원치 않으면 이 줄들을 삭제)
  limit_train_batches: 100  # 훈련 시 100개의 배치만 사용
  limit_val_batches: 50     # 검증 시 50개의 배치만 사용
  limit_test_batches: 50    # 테스트 시 50개의 배치만 사용

  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: "./output/probe.MTGTop50.MuQ-quicktest/checkpoints/" # [선택] 경로 변경
        filename: "best"
        save_top_k: 1
    - class_path: marble.modules.callbacks.LoadLatestCheckpointCallback
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
    - class_path: lightning.pytorch.callbacks.early_stopping.EarlyStopping
      init_args:
        monitor: "val/auroc"
        check_on_train_epoch_end: false
        patience: 10
        mode: "max"


logger:
  class_path: lightning.pytorch.loggers.WandbLogger
  init_args:
    project: "marble"
    name: "probe.MTGTop50.MuQ-quicktest" # [선택] 실험 이름 변경
    save_dir: "./output/probe.MTGTop50.MuQ-quicktest/" # [선택] 저장 경로 변경

# ======================================================================
# 아래 model, data, optimizer, lr_scheduler 블록은 전혀 수정하지 않습니다.
# ======================================================================

model:
  class_path: marble.tasks.MTGTop50.probe.ProbeAudioTask
  init_args:
    sample_rate: 24000
    use_ema: false

    encoder:
      class_path: marble.encoders.MuQ.model.MuQ_Encoder
      init_args:
        pre_trained_folder: null
        train_mode: freeze  # also supports lora, or full
      
    emb_transforms:
      - class_path: marble.modules.transforms.MLPReduce
        init_args:
          num_layers: 13
          hidden_size: 1024
      - class_path: marble.modules.transforms.TimeAvgPool # (batch_size, num_layers, 1, hidden_size)
    
    decoders:
      - class_path: marble.modules.decoders.MLPDecoder
        init_args:
          in_dim: 1024
          out_dim: 50 # 10 genres
          hidden_layers: [512]
          activation_fn: 
            class_path: torch.nn.ReLU
          dropout: 0.2

    losses:
      - class_path: torch.nn.BCEWithLogitsLoss

    metrics:
      train:
        f1:
          class_path: torchmetrics.F1Score # ADD
          init_args:
            task: multilabel
            num_labels: 50
            average: macro # Can be 'micro', 'macro', or 'weighted'
        f1_micro:
          class_path: torchmetrics.F1Score # ADD
          init_args:
            task: multilabel
            num_labels: 50
            average: micro # Can be 'micro', 'macro', or 'weighted'
      val:
        f1:
          class_path: torchmetrics.F1Score # ADD
          init_args:
            task: multilabel
            num_labels: 50
            average: macro # Can be 'micro', 'macro', or 'weighted'
        auroc:
          class_path: torchmetrics.AUROC # ADD
          init_args:
            task: multilabel
            num_labels: 50
            average: macro
        ap:
          class_path: torchmetrics.AveragePrecision # ADD
          init_args:
            task: multilabel
            num_labels: 50
            average: macro
        f1_micro:
          class_path: torchmetrics.F1Score # ADD
          init_args:
            task: multilabel
            num_labels: 50
            average: micro # Can be 'micro', 'macro', or 'weighted'
      test:
        f1:
          class_path: torchmetrics.F1Score # ADD
          init_args:
            task: multilabel
            num_labels: 50
            average: macro # Can be 'micro', 'macro', or 'weighted'
        f1_micro:
          class_path: torchmetrics.F1Score # ADD
          init_args:
            task: multilabel
            num_labels: 50
            average: micro # Can be 'micro', 'macro', or 'weighted'
        auroc:
          class_path: torchmetrics.AUROC # ADD
          init_args:
            task: multilabel
            num_labels: 50
            average: macro
        ap:
          class_path: torchmetrics.AveragePrecision # ADD
          init_args:
            task: multilabel
            num_labels: 50
            average: macro
    
data:
  class_path: marble.tasks.MTGTop50.datamodule.MTGTop50DataModule
  init_args:
    batch_size: 32
    num_workers: 32

    train:
      class_path: marble.tasks.MTGTop50.datamodule.MTGTop50AudioTrain
      init_args:
        sample_rate: 24000
        channels: 1
        clip_seconds: 30
        min_clip_ratio: 0.8 # at least 80% of the clip length
        channel_mode: mix # first, random, mix
        backend: "soundfile" # or "sox_io"
        jsonl: data/MTG/MTGTop50.train.jsonl
    val:
      class_path: marble.tasks.MTGTop50.datamodule.MTGTop50AudioVal
      init_args:
        sample_rate: 24000
        channels: 1
        clip_seconds: 30
        min_clip_ratio: 0.8
        channel_mode: mix
        backend: "soundfile" # or "sox_io"
        jsonl: data/MTG/MTGTop50.val.jsonl
    test:
      class_path: marble.tasks.MTGTop50.datamodule.MTGTop50AudioTest
      init_args:
        sample_rate: 24000
        channels: 1
        clip_seconds: 30
        min_clip_ratio: 0.8
        channel_mode: mix
        backend: "soundfile" # or "sox_io"
        jsonl: data/MTG/MTGTop50.test.jsonl

optimizer:
  class_path: torch.optim.Adam
  init_args:
    lr: 1e-3

lr_scheduler:
  class_path: lightning.pytorch.cli.ReduceLROnPlateau
  init_args:
    mode: "max"
    factor: 0.5
    patience: 3
    monitor: "val/auroc"
